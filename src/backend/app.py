import streamlit as st
from PIL import Image
import tempfile
import os
import sys
from transformers import AutoTokenizer

token = st.secrets["HF_TOKEN"]

tokenizer = AutoTokenizer.from_pretrained(
    "OpenGVLab/InternVL3_5-1B",
    use_auth_token=token
)

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from ai_logic import InternVLModel
from streaming.inference_multi import (
    process_video_with_inference,
    analyze_full_video,
    format_results
)


# Configuration Streamlit

st.set_page_config(page_title="InternVL ‚Äì Image & Video Analyzer", layout="centered")
st.title("Analyse d‚Äôimages et vid√©os")


@st.cache_resource
def load_model():
    return InternVLModel(streaming_mode=True)

st.sidebar.write("‚ö° Chargement du mod√®le IA...")
model = load_model()
st.sidebar.write("Mod√®le pr√™t")


mode = st.radio(
    "Que voulez-vous analyser ?",
    ("Image", "Vid√©o")
)


# MODE IMAGE
if mode == "Image":
    st.subheader("Capture d'image via webcam")

    img_file = st.camera_input("Prends une photo")

    if img_file is not None:
        image = Image.open(img_file).convert("RGB")
        st.image(image, caption="Image captur√©e", use_container_width=True)

        with st.spinner(" Analyse IA en cours..."):
            response = model.analyze_frame(
                image,
                max_new_tokens=40
            )

        st.markdown("### R√©sultat IA")
        st.write(response)


# MODE VID√âO

elif mode == "Vid√©o":
    st.subheader("Uploader une vid√©o")

    uploaded_video = st.file_uploader(
        "Choisissez une vid√©o (mp4, avi, mov)",
        type=["mp4", "avi", "mov"]
    )

    if uploaded_video is not None:
        # Sauvegarde temporaire
        temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        temp_video.write(uploaded_video.read())
        temp_video.close()

        st.success("Vid√©o upload√©e avec succ√®s")
        st.video(temp_video.name)

        # Choix du type d‚Äôanalyse
        analysis_mode = st.radio(
            "Type d'analyse",
            (
                "Description globale de la vid√©o",
                "Analyse segment par segment"
            )
        )

        # Param√®tre commun
        num_segments = st.slider(
            "Nombre de segments / frames analys√©s",
            min_value=2,
            max_value=12,
            value=4
        )

        # ANALYSE GLOBALE
        if analysis_mode == "Description globale de la vid√©o":
            st.info(" Analyse globale de la vid√©o")

            with st.spinner("Analyse en cours..."):
                result = analyze_full_video(
                    video_path=temp_video.name,
                    model=model,
                    num_segments=num_segments
                )

            st.subheader("üìù Description compl√®te")
            st.write(result)

        # ANALYSE PAR SEGMENTS
        elif analysis_mode == "Analyse segment par segment":
            st.info(" Analyse segment√©e de la vid√©o")

            with st.spinner("Analyse en cours..."):
                results = process_video_with_inference(
                    video_path=temp_video.name,
                    num_segments=num_segments,
                    model=model,
                    cleanup_segments=True
                )

            st.subheader(" R√©sultats par segment")
            st.markdown(format_results(results, output_format="markdown"))
